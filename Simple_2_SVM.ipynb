{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_2_SVM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfZTNR0YAAUFgzi9YGZGdq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilyCY/CIFAR10-Image-Classification/blob/Kman/Simple_2_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attempt to load CIFAR10 to numpy array"
      ],
      "metadata": {
        "id": "IJ4Ilas3yB-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cifar10_web\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR1iMQYS3rdB",
        "outputId": "af36cc24-ac30-4dc1-8933-1fa006f698e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cifar10_web\n",
            "  Downloading cifar10_web-0.0.4-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: cifar10-web\n",
            "Successfully installed cifar10-web-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ciUuUh3s2Vp7"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def cifar10(path=r'C:\\Users\\krist\\OneDrive\\University\\Machine Learning COS80027\\Project 3'):\n",
        "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
        "\n",
        "    Args:\n",
        "        path (str): Directory containing CIFAR-10. Default is\n",
        "            /home/USER/data/cifar10 or C:\\Users\\USER\\data\\cifar10.\n",
        "            Create if nonexistant. Download CIFAR-10 if missing.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
        "            a matrix. Rows are examples. Columns of images are pixel values,\n",
        "            with the order (red -> blue -> green). Columns of labels are a\n",
        "            onehot encoding of the correct class.\n",
        "    \"\"\"\n",
        "    url = 'https://www.cs.toronto.edu/~kriz/'\n",
        "    tar = 'cifar-10-binary.tar.gz'\n",
        "    files = ['cifar-10-batches-bin/data_batch_1.bin',\n",
        "             'cifar-10-batches-bin/data_batch_2.bin',\n",
        "             'cifar-10-batches-bin/data_batch_3.bin',\n",
        "             'cifar-10-batches-bin/data_batch_4.bin',\n",
        "             'cifar-10-batches-bin/data_batch_5.bin',\n",
        "             'cifar-10-batches-bin/test_batch.bin']\n",
        "\n",
        "    if path is None:\n",
        "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist\n",
        "        path = os.path.join(os.path.expanduser('~'), 'data', 'cifar10')\n",
        "\n",
        "    # Create path if it doesn't exist\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "\n",
        "    # Download tarfile if missing\n",
        "    if tar not in os.listdir(path):\n",
        "        urlretrieve(''.join((url, tar)), os.path.join(path, tar))\n",
        "        print(\"Downloaded %s to %s\" % (tar, path))\n",
        "\n",
        "    # Load data from tarfile\n",
        "    with tarfile.open(os.path.join(path, tar)) as tar_object:\n",
        "        # Each file contains 10,000 color images and 10,000 labels\n",
        "        fsize = 10000 * (32 * 32 * 3) + 10000\n",
        "\n",
        "        # There are 6 files (5 train and 1 test)\n",
        "        buffr = np.zeros(fsize * 6, dtype='uint8')\n",
        "\n",
        "        # Get members of tar corresponding to data files\n",
        "        # -- The tar contains README's and other extraneous stuff\n",
        "        members = [file for file in tar_object if file.name in files]\n",
        "\n",
        "        # Sort those members by name\n",
        "        # -- Ensures we load train data in the proper order\n",
        "        # -- Ensures that test data is the last file in the list\n",
        "        members.sort(key=lambda member: member.name)\n",
        "\n",
        "        # Extract data from members\n",
        "        for i, member in enumerate(members):\n",
        "            # Get member as a file object\n",
        "            f = tar_object.extractfile(member)\n",
        "            # Read bytes from that file object into buffr\n",
        "            buffr[i * fsize:(i + 1) * fsize] = np.frombuffer(f.read(), 'B')\n",
        "\n",
        "    # Parse data from buffer\n",
        "    # -- Examples are in chunks of 3,073 bytes\n",
        "    # -- First byte of each chunk is the label\n",
        "    # -- Next 32 * 32 * 3 = 3,072 bytes are its corresponding image\n",
        "\n",
        "    # Labels are the first byte of every chunk\n",
        "    labels = buffr[::3073]\n",
        "\n",
        "    # Pixels are everything remaining after we delete the labels\n",
        "    pixels = np.delete(buffr, np.arange(0, buffr.size, 3073))\n",
        "    images = pixels.reshape(-1, 3072).astype('float32') / 255\n",
        "\n",
        "    # Split into train and test\n",
        "    train_images, test_images = images[:50000], images[50000:]\n",
        "    train_labels, test_labels = labels[:50000], labels[50000:]\n",
        "\n",
        "    def _onehot(integer_labels):\n",
        "        \"\"\"Return matrix whose rows are onehot encodings of integers.\"\"\"\n",
        "        n_rows = len(integer_labels)\n",
        "        n_cols = integer_labels.max() + 1\n",
        "        onehot = np.zeros((n_rows, n_cols), dtype='uint8')\n",
        "        onehot[np.arange(n_rows), integer_labels] = 1\n",
        "        return onehot\n",
        "\n",
        "    return train_images, _onehot(train_labels), \\\n",
        "        test_images, _onehot(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "51RM3En-Lo1f",
        "outputId": "7529fe71-562d-4855-9aab-b18f78911136"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-2fb49f6fb0b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CIFAR10 via Numpy thanks to Matt Peterson: https://mattpetersen.github.io/load-cifar10-with-numpy"
      ],
      "metadata": {
        "id": "ghmWgoPP2sER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "oa1q525624lm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def cifar10(path=\"C:\\Users\\krist\\OneDrive\\University\\Machine Learning COS80027\\Project 3\")"
      ],
      "metadata": {
        "id": "W-ljgM-_2di_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.cs.toronto.edu/~kriz/'\n",
        "tar = 'cifar10python.tar.gz'\n",
        "files = ['cifar-10-batches-bin/data_batch_1.bin',\n",
        "        'cifar-10-batches-bin/data_batch_2.bin',\n",
        "        'cifar-10-batches-bin/data_batch_3.bin',\n",
        "        'cifar-10-batches-bin/data_batch_4.bin',\n",
        "        'cifar-10-batches-bin/data_batch_5.bin',\n",
        "        'cifar-10-batches-bin/test_batch.bin']"
      ],
      "metadata": {
        "id": "9brq9PkN7mPp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from tarfile\n",
        "with tarfile.open(os.path.join(path, tar)) as tar_object:\n",
        "        # Each file contains 10,000 color images and 10,000 labels\n",
        "        fsize = 10000 * (32 * 32 * 3) + 10000\n",
        "\n",
        "        # There are 6 files (5 train and 1 test)\n",
        "        buffr = np.zeros(fsize * 6, dtype='uint8')\n",
        "\n",
        "        # Get members of tar corresponding to data files\n",
        "        # -- The tar contains README's and other extraneous stuff\n",
        "        members = [file for file in tar_object if file.name in files]\n",
        "\n",
        "        # Sort those members by name\n",
        "        # -- Ensures we load train data in the proper order\n",
        "        # -- Ensures that test data is the last file in the list\n",
        "        members.sort(key=lambda member: member.name)\n",
        "\n",
        "        # Extract data from members\n",
        "        for i, member in enumerate(members):\n",
        "            # Get member as a file object\n",
        "            f = tar_object.extractfile(member)\n",
        "            # Read bytes from that file object into buffr\n",
        "            buffr[i * fsize:(i + 1) * fsize] = np.frombuffer(f.read(), 'B')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "5nQAjl7J5_h3",
        "outputId": "1c0a31e6-b209-40c6-a298-1bcb3d33ad63"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-87e1aa05e450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data from tarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;31m# Each file contains 10,000 color images and 10,000 labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1573\u001b[0m                     \u001b[0msaved_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1575\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1576\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mReadError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompressionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/tarfile.py\u001b[0m in \u001b[0;36mgzopen\u001b[0;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\krist\\\\OneDrive\\\\University\\\\ML_COS80027\\\\Project3/cifar10python.tar.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file='cifar10python.tar.gz'"
      ],
      "metadata": {
        "id": "lSNQv0zMHVXe"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n",
        "\n",
        "\n",
        "batch1=unpickle(\"data/data_batch_1\")\n",
        "batch2=unpickle(\"data/data_batch_2\")\n",
        "batch3=unpickle(\"data/data_batch_3\")\n",
        "batch4=unpickle(\"data/data_batch_4\")\n",
        "batch5=unpickle(\"data/data_batch_5\")\n",
        "test_batch=unpickle(\"data/test_batch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "bUFfgHzcHAsV",
        "outputId": "2185d162-e889-4db1-d46c-8649917c1f14"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-c8be610b0be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbatch1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/data_batch_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mbatch2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/data_batch_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbatch3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/data_batch_3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-c8be610b0be8>\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bytes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/data_batch_1'"
          ]
        }
      ]
    }
  ]
}
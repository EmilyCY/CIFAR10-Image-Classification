{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_LogisticRegression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPHPyMzLXk2ozXvA622RZ6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "887b612b4acc4cfab72b23343ee2cdf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68307860fccb4caeaa27af2c0d69a80a",
              "IPY_MODEL_a9e0a35d2bf94c00aba44e3434d04307",
              "IPY_MODEL_96b1104b108b4fbda3363395c7a06678"
            ],
            "layout": "IPY_MODEL_8666421c909a4a67bcd060cbb49c723e"
          }
        },
        "68307860fccb4caeaa27af2c0d69a80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_496f20b0622941e5b13fbd95cd672e9c",
            "placeholder": "​",
            "style": "IPY_MODEL_a54ce2c534e944d29786e1abe57cc6ca",
            "value": ""
          }
        },
        "a9e0a35d2bf94c00aba44e3434d04307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_411e7387f4604c54be4864814fd68535",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef88170f901746019d63cce9f04aa5d2",
            "value": 170498071
          }
        },
        "96b1104b108b4fbda3363395c7a06678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2b209f2ca64f9d97f53c8c9d0c9300",
            "placeholder": "​",
            "style": "IPY_MODEL_62b54507a1354ceb912264d5f444b664",
            "value": " 170499072/? [00:03&lt;00:00, 40533703.10it/s]"
          }
        },
        "8666421c909a4a67bcd060cbb49c723e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496f20b0622941e5b13fbd95cd672e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a54ce2c534e944d29786e1abe57cc6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "411e7387f4604c54be4864814fd68535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef88170f901746019d63cce9f04aa5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e2b209f2ca64f9d97f53c8c9d0c9300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62b54507a1354ceb912264d5f444b664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilyCY/CIFAR10-Image-Classification/blob/Kman/Pytorch_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch version (incomplete)"
      ],
      "metadata": {
        "id": "qXKHat9kyVja"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0NswDi-YNmrj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set matplotlib to inline\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Cff5TgUFh46I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#do we want to use PCIKLE to load the data??\n",
        "#def unpickle(file):\n",
        "    #import pickle\n",
        "   # with open(file, 'rb') as fo:\n",
        "        #dict = pickle.load(fo, encoding='bytes')\n",
        "    #return dict"
      ],
      "metadata": {
        "id": "KSq3zHMKOMR3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The file has 60000 rows, each row contains a single index into the tiny db,\n",
        "where the first image in the tiny db is indexed \"1\". \"0\" stands for an image that is not from the tiny db.\n",
        "The first 50000 lines correspond to the training set, and the last 10000 lines correspond\n",
        "to the test set."
      ],
      "metadata": {
        "id": "l-31B7_bOl1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "b-uG9XYQaLee"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process: Import dataset\n",
        "Transform images to RGB matrices of 3x32x32.\n",
        "\n",
        "Data partitioning into 50k training and 10k test sets\n",
        "\n",
        "Via SubsetRandomSampler, the dataset is shuffled once again into an iterative object.\n",
        "\n",
        "Via DataLoader, the randomly shuffled indexes paired with corresponding image matrices, in preset batches decided by batchSize.\n",
        "\n",
        "Modify the nn.linear function by editing the class nn.model, and making it so that nn.linear automatically flattens a matrix before entering it in nn.linear\n",
        "\n",
        "Inputting the number of classes (X's rows) and number of features (X's columns) into nn.linear gives us a model, and empty set of thetas to multiply something by.\n",
        "\n",
        "By iterating through our trainLoader, which contains both the image matrix and the labels, we can input the image matrices through our model to get our outputs."
      ],
      "metadata": {
        "id": "snr_VP55sN5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the training set (first 50,000 imgs) by setting train=True.\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True)\n",
        "# import the test set (10,000 imgs) by setting train=False\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "# define the ten labels manually.\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "887b612b4acc4cfab72b23343ee2cdf9",
            "68307860fccb4caeaa27af2c0d69a80a",
            "a9e0a35d2bf94c00aba44e3434d04307",
            "96b1104b108b4fbda3363395c7a06678",
            "8666421c909a4a67bcd060cbb49c723e",
            "496f20b0622941e5b13fbd95cd672e9c",
            "a54ce2c534e944d29786e1abe57cc6ca",
            "411e7387f4604c54be4864814fd68535",
            "ef88170f901746019d63cce9f04aa5d2",
            "0e2b209f2ca64f9d97f53c8c9d0c9300",
            "62b54507a1354ceb912264d5f444b664"
          ]
        },
        "id": "HPJzcZQ3aMu1",
        "outputId": "d63cf244-5b9a-4605-a659-542feaa194db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "887b612b4acc4cfab72b23343ee2cdf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the data is loaded correctly\n",
        "#data sholuld be loaded as a tuple\n",
        "print(\"This is the length of the trainset: \",len(trainset))\n",
        "print(\"This is the length of the testset: \",len(testset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thkdddlmi9Id",
        "outputId": "6cd24559-a0c2-441f-b25a-7d3bd4df5814"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the length of the trainset:  50000\n",
            "This is the length of the testset:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset)"
      ],
      "metadata": {
        "id": "b8qgT5bjmS7_",
        "outputId": "f5eedd0d-5a6b-4f18-9563-36e949d9de66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data\n",
            "    Split: Train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(testset)"
      ],
      "metadata": {
        "id": "8aZMb4zrmWPk",
        "outputId": "c47cadde-c4e6-4852-c809-bfa61f4ed9f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset CIFAR10\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data\n",
            "    Split: Test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Look at some of the images downloaded"
      ],
      "metadata": {
        "id": "F3V-s0GKgxsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = 1999\n",
        "image, label = trainset[example] #since each element of the trainset list is itself a tuple with the image details, and then the label\n",
        "print(\"this is an image of a \" + classes[(trainset[example])[1]]) # first index into tuple in trainset, then the 2nd value (label), and then the classes\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "mKek_CpOewte",
        "outputId": "0af52c37-9ad4-4ebb-e0da-70cbff4026f2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is an image of a plane\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fbd460eacd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Examine the format it is supplied in\n",
        "#Image is supplied as PIL\n",
        "print(trainset[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USQnOLbH0Niz",
        "outputId": "91d31270-9175-4738-b148-33bfb8a7ba42"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7FBD46D91E50>, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transforming images into matrices of color values"
      ],
      "metadata": {
        "id": "LYS7ElZt55L4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This transforms the image into a matrices of colours for each pixel"
      ],
      "metadata": {
        "id": "zpQRyVQ56ENa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#transform images into RGB\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "x2PK94912MBb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasetT = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transforms.ToTensor())\n",
        "print(datasetT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjg_ns2I3xuL",
        "outputId": "30fc799d-6a72-4847-f995-f20be58af0c0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Examine the format it is supplied in\n",
        "#Image is supplied as PIL\n",
        "#QUESITON: why is this the same as prior to transform? Check how it was loaded. Did this occur in the loading stage?\n",
        "print(trainset[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKIaa6Nu3zHi",
        "outputId": "20ef7fb2-2555-46f6-e8b7-ca8afc4f5ca9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<PIL.Image.Image image mode=RGB size=32x32 at 0x7FBD45A73CD0>, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This is how to show the shape!!\n",
        "imgTensor, label = datasetT[example]\n",
        "print('size of image matrix: ' + str(imgTensor.shape))\n",
        "print(\"this is an image of a \" + classes[(trainset[example])[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNNZlHjj4qML",
        "outputId": "48514916-59cb-42eb-a876-7bac5f11229d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of image matrix: torch.Size([3, 32, 32])\n",
            "this is an image of a plane\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Look at the pixel values for the bottom 4 pixels (2x2)\n",
        "print(imgTensor[:, 0:2, 0:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM8PNZ5D5AY4",
        "outputId": "4d0d26a4-44c4-443e-8a67-189f60375a27"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.4863, 0.4941],\n",
            "         [0.5255, 0.5647]],\n",
            "\n",
            "        [[0.7451, 0.7255],\n",
            "         [0.7412, 0.6863]],\n",
            "\n",
            "        [[0.8824, 0.8431],\n",
            "         [0.8784, 0.8078]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the image from the imgTensor values\n",
        "#limit the colours to Blues\n",
        "imgTensor, label = datasetT[example]\n",
        "plt.imshow(imgTensor[1, 0:64, 0:64], cmap='Blues')\n",
        "# change the 0 to 1 or 2 for different color channels.\n",
        "print(\"R channel of image 0 in dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "-sPLX6Tl5NFC",
        "outputId": "56c29bed-62d7-46ea-9d3d-2529b18c76c6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R channel of image 0 in dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the image from the imgTensor values\n",
        "#limit the colours to Blues\n",
        "imgTensor, label = datasetT[example]\n",
        "plt.imshow(imgTensor[0, 0:3072, 0:3072])\n",
        "# change the 0 to 1 or 2 for different color channels.\n",
        "print(\"R channel of image 0 in dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "p7FOI79ByUN_",
        "outputId": "e5b33b36-6b3d-49b2-fb1f-02ddb88ed5af"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R channel of image 0 in dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZSklEQVR4nO2dbYycV3XH/2dedvbd67Ude712MHHMS4DGhFVIC4p4KWmgSA5tFYFUlA8pRi1RiwQfolCVVGoRVAWUShXUlCgBpQnhTUQlogQLEYUWk3Xi2I4NIS822Y3tjV/WXu+ud3ZmTj/MY2kd3XN29tmZZza5/59kefY5c+89c+c5zzNz/3POFVUFIeS1T67dDhBCsoHBTkgkMNgJiQQGOyGRwGAnJBIY7IREQmE5jUXkRgB3AcgD+E9V/aL3/HxfjxbWrE4xkHG8tvSuSFZYbxql3qZgTG/l1BlUp6aD1tTBLiJ5AP8O4AMAxgA8LiIPqeohq01hzWps+Nzfho155ySwbBfyjbp7KdZ5+FrAmsaMY0xq4UnWnOOI976k9f/V/F57r9mIieP//G9mk+V8jL8WwLOq+ryqlgE8AGDHMvojhLSQ5QT7MIAXF/w9lhwjhKxAWr5AJyI7RWRUREarU9OtHo4QYrCcYB8HsHnB35uSY5egqrtUdURVR/J9PcsYjhCyHJYT7I8D2CYirxeRDgAfBfBQc9wihDSb1KvxqloRkdsA/A/q0tvdqvq010byimJ/OWhb1Te7ZB9One61/ZtzVuqlyUvT2oIl37Q+Wr5kLFNqmttIs98X4LX7SxJLoXJOxWXp7Kr6MICHl9MHISQbXqvXPULIK2CwExIJDHZCIoHBTkgkMNgJiYRlrcYvlVxO0dM9F7SVChWz3eRMV7i/gq0nVcvOdSztJc4azpOMsr6c1gxfcinlQe+1uZIjs9tWGryzExIJDHZCIoHBTkgkMNgJiQQGOyGRkO1qvNTQ1xlejd/UO2m2G39pMGxwVtxzPfOmrVZJeY1LWQUrU0wfW7E6nmKlvhXJLmlYSclLFlXHxxRj8c5OSCQw2AmJBAY7IZHAYCckEhjshEQCg52QSMhUelMIytWwNjTQsfQadPlp51rVb0sToo6tyfKJppR40vohK+TyrStkay57/jOWAI0dcjzU2SVJUpxWK+TUIIS0GgY7IZHAYCckEhjshEQCg52QSGCwExIJy5LeROQIgCkAVQAVVR3xnq8qmJsPD/nkSXu359y5cJvcvK0/5ApV02ZXuwNyuaVrRrWafc1MreSlbJiz2mWcbVazNMBWZJs5iCGxedKgJ5fmHDnMm2P1MtjMRin8cHxohs7+XlU92YR+CCEthB/jCYmE5Qa7AvipiOwVkZ3NcIgQ0hqW+zH+3ao6LiKXAXhERH6jqo8ufEJyEdgJAMV1/cscjhCSlmXd2VV1PPl/AsAPAVwbeM4uVR1R1ZHCqp7lDEcIWQapg11EekSk7+JjADcAONgsxwghzWU5H+PXA/ih1NNvCgD+S1V/4jWo1QSzc8WgbXLc/ogvhsyQn3EKTuZtbaXmZCAVi7ZkV61a462QFC+HXC7rQo/GnGRc6DFvnDtVp+ioJ6UWirZw62WiVZ10xJoxJ5ZsCNgSsedD6mBX1ecBXJ22PSEkWyi9ERIJDHZCIoHBTkgkMNgJiQQGOyGRkG3BSQXm58JDyrx93enaNBU8nj+yymwz78gnlhwDePKaLdl5slaawoCtwKmxmRrvtdlzskL2evNoRYag06eZqehgScReoVLe2QmJBAY7IZHAYCckEhjshEQCg52QSMh0NT6XU/T2XQjapp0V8jdfdiJ4/MnNfWab2ulO0za48axpm5q221krzIXCykmEsVbdveSOVpA3EpFaoU54SoP1ur1EKW+mfAXCOw+aO/9pEpt4ZyckEhjshEQCg52QSGCwExIJDHZCIoHBTkgkZCq91ao5TE12B206mzfbjQ0MBI9f/pZjZpujh4ZMW6Vqj9XXE5YGAaBcCU+Xt11QMW/XtGsFVj0zeDX5WlAXrmDIUGm21wJ86dDzP82uS14yifdeexSc7cjS0FEI18JjIgwhhMFOSCww2AmJBAY7IZHAYCckEhjshETCotKbiNwN4MMAJlT1rcmxQQDfAbAFwBEAN6vqmcX66i7NYeTKI0Hbxi47E21VYTZ4fGspnA0HALuq15u28efXmrYt2+w+T54PT9fMS71mm/VbT5q2csWWAHNNVsPyjuQ179Td80jjo+eHRxoJDQBqGpa8io4UmVZ68+bRm6taipJ3lv9uVl4D/d4D4MZXHLsdwG5V3QZgd/I3IWQFs2iwJ/utn37F4R0A7k0e3wvgpib7RQhpMmm/s69X1Ys/XzuO+o6uhJAVzLIX6FRV4RQDF5GdIjIqIqNzk/ZPUQkhrSVtsJ8QkSEASP6fsJ6oqrtUdURVR0oDdsknQkhrSRvsDwG4JXl8C4AfNccdQkiraER6ux/AewCsFZExAJ8H8EUAD4rIrQCOAri5kcE2dJzDZ4d/ErTlnW2B+nLzweP3TV5rtvnA0G9M2z0v/ZFpO3psjWm7bO254PHZOVvvWN993rRNzZdM27yTmddsqk5G2cxc0bT1d9tfy1aVwra5qn3Kea/ZyqJLy5yRwQgAF+Ztm5VtBvjymic5pnmnezrKhg92HC0a7Kr6McP0/oa8IoSsCPgLOkIigcFOSCQw2AmJBAY7IZHAYCckEjItOHm22oUfn9setJXEljQ2doQT6oaN4wDwltKYaRt857Rp+/GJt5q23uJc8PjJDfaeczetf9K0vVRebdpOzfeYtlLOnqvfzw6aNovzjgR4tGr7uK7bnsfrVr8QPD6n9ik3NmuPNT6zyrR15u356DBsL0zaEuv8fDrZc3V3ODsTAMYnwkVTAaBYCvt42Spbth0/HZ6PeS+T0rQQQl5TMNgJiQQGOyGRwGAnJBIY7IREAoOdkEjIVHqbqxXx3PS6oG24a9Jsd3XhaPD4O0unzDZPzNlSx7GyLeMMlmZM2+GT4YI81bJ9zRzM2/JJZymczQcAa4tdpu3QzEbT9uxkuJjmhp4ps82aki2hlfttKWd9p93nYCH8uqdqdk2DgaI991MdtjzYUwhngAHAYDH82rz94cZy9rnTVbTfMy/jzCtUWZ4I739YHLSLsFZeDEuz6pyLvLMTEgkMdkIigcFOSCQw2AmJBAY7IZGQ6Wr8+fOd2PPYm5fc7rsbrgkef8Mme6um9657xrQdmbGTIF6+YG/ldPZIeJW2OGOvtP7y/BtM2+mynewyXemw282FV28B4PTZcJ8nTtgKxIYNthJyw0a7ll9v3q5BN5APr6zPO4kwa4yVc8BP/pmr2X1Ozofn6owzh972T10FezX+3JytNHjn6jNPbwoef+mx8HEAKOTCPopTqo93dkIigcFOSCQw2AmJBAY7IZHAYCckEhjshERCI9s/3Q3gwwAmVPWtybE7AXwCwMvJ0+5Q1YcXHS2vqKwKSyilE7Yr3XvDksbz45ebbd77YVt62/PrN5q2njH7+jf0YljXyFVsvWP0Z+8wbdWSPdbYX9oSz99fY0/1L3u2BY/v/tXbzDbHK3bduhveeMC0bTDkNQDYWgxLmMcqL5ptniiHk3gA4KriSdNWdLZduv/c1cHjv5+269392eZ9pu0nx99i2rwtpf5qy2Om7QsTYSm4+4AtzV74k/BWZNJVNds0cme/B8CNgeNfVdXtyb/FA50Q0lYWDXZVfRTA6Qx8IYS0kOV8Z79NRPaLyN0iYn8mIoSsCNIG+9cAbAWwHcAxAF+2nigiO0VkVERGq1P2zyEJIa0lVbCr6glVrapqDcA3AJgbpavqLlUdUdWRfJ+94EAIaS2pgl1Ehhb8+REAB5vjDiGkVTQivd0P4D0A1orIGIDPA3iPiGwHoACOAPhkI4P1d8/ig9eEpZwJL9usHK7H9uwL4ZpwAPAfv3ifadOSLZXNvMPO5MoZGVQDz9ky2ZltdvbazJCtGe14417TNlW169Nd2T0RPP6LWXus0ljRtN15xQ7TtqrD3u7obf0vBY9/sP8ps00Rtmx0oHyZaXtTx8um7arO8fBYG+yxrugIzyEA3HP2OtM2/0y/aft67nrTlj8UPvcHD9nS5u8vD4+ls3bNwEWDXVU/Fjj8zcXaEUJWFvwFHSGRwGAnJBIY7IREAoOdkEhgsBMSCaJqF9drNqUrhnX4C38TtFVnHGGgGpaNCpN2m6H/taWVmctseaLcZ0tUq16w+7QY+1OnTd6e++JxW7Kr9NnSoXaGx1u915bXuk7a/Z3fZM+VOreK8qrwaytvmTPbbB22JbTZedv/iUlbtp0/G942Srxtksr2OdB13G7Xecp+P/Nztm3Vc2GJrTxgb3lV6Q778dTuu3D+zIvBF8A7OyGRwGAnJBIY7IREAoOdkEhgsBMSCQx2QiIh073ecjM59DwezhzLX7ClCTHUq0qXLZHMrLUlo9KkLTV1T9h+FKbDjhRmbXltYJ+9p9j0sD1W/7OmCbmKfY3OG7JR90TZbFMr2v2t3W/vsSY12/9qKTz/s7+1JcVjmzebtpztPtaN2e9nbn7p0nKtYLfRvD3WfLcj2Z2yz5HZ9eGCqudeZ4dn56mwH54cyjs7IZHAYCckEhjshEQCg52QSGCwExIJma7GQwFYi5nOoqm1wuglF9TsvAlcWG1f47zVzI7zYWPfEXultTCdLtFoZoOzsvuyo1xouF25336rK532WIU5J2HEWem2bH1jdiKM1OzEj+mNth9nttm2alfYj1zF2TPKofdouvdzer09/zVDoFBbUMLU5eHXbPUF8M5OSDQw2AmJBAY7IZHAYCckEhjshEQCg52QSGhk+6fNAL4FYD3qAtkuVb1LRAYBfAfAFtS3gLpZVc94fdU6gBkj+SNn76Bk+5ZSPhFX5rONFwwZqlq0t2Na/Yy9RdK6X9m72lYG7ASasT+2N8isdob97zhr6ziVcB4GAH+uXAyJdfgX9hs9+H/hLaMAQK7baNrO/Lk9j/1dYanv1Gm7bl1fv/2enSsMmLbieft8FDt/xpR7PRm4aqiUy02EqQD4jKpeBeA6AJ8SkasA3A5gt6puA7A7+ZsQskJZNNhV9ZiqPpE8ngJwGMAwgB0A7k2edi+Am1rlJCFk+SzpO7uIbAHwdgB7AKxX1WOJ6TjqH/MJISuUhoNdRHoBfB/Ap1X13EKb1ovPB7/dichOERkVkdHaefu7FSGktTQU7CJSRD3Q71PVHySHT4jIUGIfAhDc1FpVd6nqiKqO5HrthSVCSGtZNNhFRFDfj/2wqn5lgekhALckj28B8KPmu0cIaRaNZL29C8DHARwQkX3JsTsAfBHAgyJyK4CjAG5etCcBql1hDaJWXLps4dUlc6U8IzMMAPIXHDnPkKHK/U7W2Gn7q0v18O9MW3HzJtsPONJbydh2aZXdm5dd5ddjc/o0biPVTrtRdfy4aRt40k7nOvW2dabtdHd4rjqm7PesXLO1yLxzXlUdCTNnJ/shZ5T5y9sKIPJGf1a9RqCBYFfVxwBYM/P+xdoTQlYG/AUdIZHAYCckEhjshEQCg52QSGCwExIJ2W7/NA90HXP0GgNLKfNkEE968yS7jilbauqYCmuA+Tk7panW68g4b95mtyvZFTPXHLT1lZr5jjrpa2LLUF4WlaNgmnhbZeWHN9hjFezzZuiXzhZVVUOK7He2Bztj96d5+0XXOpxtuZzXbfVp+Q4AlZ6w/14RVt7ZCYkEBjshkcBgJyQSGOyERAKDnZBIYLATEgnZ7vUGO4PNk3Esky0zATVH4RN7SzFUnX3PLqwOdype+teVtoQmtT67naeU1byKmeHDrhRpK01+cU7nPcsZstH0sJMatnHI6c9u5klUWgrfz8q99n1uesg+QXJle6zijGlCvsfZX9CYR2/uqx3hRp40yDs7IZHAYCckEhjshEQCg52QSGCwExIJma7Ga86p0+Vtj2MsdnuryG6ShretjrNYbG0N5ddwc/zwFAhnPryVenPV3ZU70i25e/XOpBpu566qO6/ZG6tmCx6p8MaqdDtqzRqnz9rSs4a889s6d7y54J2dkEhgsBMSCQx2QiKBwU5IJDDYCYkEBjshkbCo9CYimwF8C/UtmRXALlW9S0TuBPAJAC8nT71DVR92+6rZ9d88mcFKavEUIy8RxpOuPCw5Cc7WPvm0l1NPhvJkOQNXxnE0QE9W9KW3RV1a0lge/lZf6fq0cOVBTz72avmZW2XZbSrdS5eBG9HZKwA+o6pPiEgfgL0i8khi+6qq/msDfRBC2kwje70dA3AseTwlIocBDLfaMUJIc1nSh0wR2QLg7QD2JIduE5H9InK3iKxusm+EkCbScLCLSC+A7wP4tKqeA/A1AFsBbEf9zv9lo91OERkVkdHKjL19MSGktTQU7CJSRD3Q71PVHwCAqp5Q1aqq1gB8A8C1obaquktVR1R1pGDslU0IaT2LBruICIBvAjisql9ZcHxhDaGPADjYfPcIIc2ikdX4dwH4OIADIrIvOXYHgI+JyHbUxY0jAD65aE8KFGbDJk+qyVnKkHOpMtsgfZaaJfWlkZnqDW2TJ9Wkkd5cN7z+UmzxBABqzKMniVptgEXeF+/ccSVHyxHH5PjhSofeHBvvda3gFSJ0+jNoZDX+MaNrV1MnhKws+As6QiKBwU5IJDDYCYkEBjshkcBgJyQSMi04KWpnKHlb+NSKxlY3Kf3w5Bh3KyRD4klb3NLD7dPB8jHtNk6uLJeiSGjekymNjEivP8DPerPmwy0E6pHSR387L6u/pZ8Ergy55N4IIa9KGOyERAKDnZBIYLATEgkMdkIigcFOSCRkKr1BYUoQvmQQblRzUn9yXmHAiq2DeHuRWVKTm0XX4RRz9DLbHDfSZNlJLZ1Q6Y3lFlEspNAOXXmquZUjzeKhgDv5afeVyztFSS3ZWb3UTcPkSaW8sxMSCQx2QiKBwU5IJDDYCYkEBjshkcBgJyQSMpXeNAdUusO2XNmR0axMrrR7azlymJfkZUlsafbxWg6pXrfYr9mVPZ2MMk9yNP3wFDRXrUuZBmiRdr8/Tx70ils67arO+WhizK+Xwcg7OyGRwGAnJBIY7IREAoOdkEhgsBMSCYuuxotIJ4BHAZSS539PVT8vIq8H8ACANQD2Avi4qjoVuupb58wNhpclvdX4NNsuufXAUqK5pS/hSs1JhEm7wOwsCdur8U53lXSOqLM9USoVIuV2WGlW+Gsd6Zbj3fM0bdJQ3kiE8c5h83XZTRp5S+YAvE9Vr0Z9e+YbReQ6AF8C8FVVvRLAGQC3NtAXIaRNLBrsWud88mcx+acA3gfge8nxewHc1BIPCSFNodH92fPJDq4TAB4B8ByASVW9+DOCMQDDrXGRENIMGgp2Va2q6nYAmwBcC+BNjQ4gIjtFZFRERqvT0yndJIQslyUto6jqJICfA/hDAAMicnGBbxOAcaPNLlUdUdWRfE/PspwlhKRn0WAXkXUiMpA87gLwAQCHUQ/6v0iedguAH7XKSULI8mkkEWYIwL0ikkf94vCgqv63iBwC8ICI/BOAJwF8c7GO6okwYZkhn2LrHC8pITVN79PLnEjXY82RvMw+vddVSudjGvkqrcxXKznZP4Z0BcC+nXltnKG8RCnv1imObJvrCGt2eaeQYrEYbmP1BTQQ7Kq6H8DbA8efR/37OyHkVQB/QUdIJDDYCYkEBjshkcBgJyQSGOyERIKotkK/MgYTeRnA0eTPtQBOZja4Df24FPpxKa82P16nqutChkyD/ZKBRUZVdaQtg9MP+hGhH/wYT0gkMNgJiYR2BvuuNo69EPpxKfTjUl4zfrTtOzshJFv4MZ6QSGhLsIvIjSLyWxF5VkRub4cPiR9HROSAiOwTkdEMx71bRCZE5OCCY4Mi8oiI/C75f3Wb/LhTRMaTOdknIh/KwI/NIvJzETkkIk+LyN8lxzOdE8ePTOdERDpF5Nci8lTixz8mx18vInuSuPmOiDjlJQOoaqb/AORRL2t1BYAOAE8BuCprPxJfjgBY24ZxrwdwDYCDC479C4Dbk8e3A/hSm/y4E8BnM56PIQDXJI/7ADwD4Kqs58TxI9M5QT2xuDd5XASwB8B1AB4E8NHk+NcB/PVS+m3Hnf1aAM+q6vNaLz39AIAdbfCjbajqowBOv+LwDtQLdwIZFfA0/MgcVT2mqk8kj6dQL44yjIznxPEjU7RO04u8tiPYhwG8uODvdharVAA/FZG9IrKzTT5cZL2qHkseHwewvo2+3CYi+5OP+S3/OrEQEdmCev2EPWjjnLzCDyDjOWlFkdfYF+jerarXAPgggE+JyPXtdgioX9nRgpo5DfI1AFtR3yPgGIAvZzWwiPQC+D6AT6vquYW2LOck4Efmc6LLKPJq0Y5gHwewecHfZrHKVqOq48n/EwB+iPZW3jkhIkMAkPw/0Q4nVPVEcqLVAHwDGc2JiBRRD7D7VPUHyeHM5yTkR7vmJBl7yUVeLdoR7I8D2JasLHYA+CiAh7J2QkR6RKTv4mMANwA46LdqKQ+hXrgTaGMBz4vBlfARZDAnIiKo1zA8rKpfWWDKdE4sP7Kek5YVec1qhfEVq40fQn2l8zkAn2uTD1egrgQ8BeDpLP0AcD/qHwfnUf/udSvqe+btBvA7AD8DMNgmP74N4ACA/agH21AGfrwb9Y/o+wHsS/59KOs5cfzIdE4A/AHqRVz3o35h+YcF5+yvATwL4LsASkvpl7+gIyQSYl+gIyQaGOyERAKDnZBIYLATEgkMdkIigcFOSCQw2AmJBAY7IZHw/+IhLfNiCpq0AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the image from the imgTensor values\n",
        "#limit the colours to Blues\n",
        "imgTensor, label = datasetT[example]\n",
        "plt.imshow(imgTensor[1, 0:3072, 0:3072])\n",
        "# change the 0 to 1 or 2 for different color channels.\n",
        "print(\"R channel of image 0 in dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "0itiqU3mymwW",
        "outputId": "83a1b08f-22f9-4d4f-9ec8-b2c8dff52d0d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R channel of image 0 in dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZPklEQVR4nO2dbYycV3XH/2dm37ze9fo16816iZ0XmqS8OLA1AVIaoEEpQkqgKAqVUCpFGCEigUQ/RKlEUlGpUDXQfCi0TjEEFAgphJK2ERAs2ohCHW9S23HiOHHCJvZie/263hfvzs7M6Yd5rK7DPWdmn5l5ZsP9/6TVzt4z97ln7vOceWbuf8+5oqoghPzuk2u1A4SQbGCwExIJDHZCIoHBTkgkMNgJiQQGOyGR0FZPZxG5EcB9APIA/llVv+g9v3dVu64Z7AzaSsib/SxxMGdaAIV4rmSGOD56NNr/tH683lkq10GjyaEcbD85Noup0/PBF5062EUkD+AfANwA4DCAXSLyqKo+Z/VZM9iJzz/y1qDtVLHHHKtknLDuXMHsM1duN21Z0i6lVP3m1X7zy9KPnIQvqmqUNfyhsdHHq0aj53Gp0JOfDbb/zZ8+bfap52P8FgAHVfVlVS0AeAjATXUcjxDSROoJ9kEAhxb8fThpI4QsQZq+QCciW0VkRERGpk7PN3s4QohBPcE+BmBowd8bkrYLUNVtqjqsqsM9q5bG92hCYqSeYN8F4AoR2SQiHQBuBfBoY9wihDSa1KvxqloUkTsA/AQV6W27qj7r9xKUjFXV0dk1Zi9rJfnSZcfNPtZqJQDkDdmiGZRSvp92Y66hfuRTroJb56sqKRSvtD4uFVLPVQp68+eC7d4c1qWzq+pjAB6r5xiEkGzgf9AREgkMdkIigcFOSCQw2AmJBAY7IZFQ12r8YilDMFMOZ739z7GNZr9iKfyedNGmSbPP2jbblqUM1SHFVGMtFV7vcliWLPW54p2dkEhgsBMSCQx2QiKBwU5IJDDYCYmETFfjAbssUUfeLpt0/PDKYPtTq99g9vnoRSOmbV7Tvey0pZ3I/5NlEtJSIk05Lu867TCuRa8uI+/shEQCg52QSGCwExIJDHZCIoHBTkgkMNgJiYRMpTeFmDu1XNwzYfYbk3B9ut9M9Zl9uvrTla22JA3A3nKn7LxnFlLuSJLGj2q+LAWaMR9p8OawGTT6vHRJ+Pr2tvla2lcGIaRhMNgJiQQGOyGRwGAnJBIY7IREAoOdkEioS3oTkVEAkwBKAIqqOuw9f17zODa/ImjzZDSUw3sJnZ0N17MDfKkmrQxiHzOdTJZuLJ+CrbxkSqOlprSSnUVHiu2p6iHNddDlZMq1G7UNPemtETr7e1X1RAOOQwhpIvwYT0gk1BvsCuCnIvKUiGxthEOEkOZQ78f461R1TEQuAvC4iDyvqk8sfELyJrAVAHoHuuscjhCSlrru7Ko6lvweB/BDAFsCz9mmqsOqOty9yl5QI4Q0l9TBLiLLRaT3/GMAHwCwr1GOEUIaSz0f4/sB/FBEzh/nO6r6Y6/DbKkNB872B21jr4Qz2wAAnWEZavK0/bXAk2o8W6Ozqxp9vLQ0IxvOk5MsmycnpaXRWYfNyCq0stQ8vLGs4+WkCdKbqr4M4K1p+xNCsoXSGyGRwGAnJBIY7IREAoOdkEhgsBMSCZkWnCyWczhxbnnQljtnSyQr1k8G26eeX2X2OVXqMW3r2+zilh5WppFHSbN9P22GtJUGSzZqhuzpZfpZ8+GN5Z1n73w2Wt5sdFFM3tkJiQQGOyGRwGAnJBIY7IREAoOdkEjIdDW+LVfG6mUzQdtYn50oMLDibLB9f1+4nh0APHbizabtMxc/btpmNbw9FWAnH5SW0Htmu7HKnG/Cdkfe6543Vt3TKBrVSHNMa56AKnPl1K5LMx9p6TJr0NksnauUENJUGOyERAKDnZBIYLATEgkMdkIigcFOSCRkKr3NFdswejqcvJKbsCWvQ2dWBtsv3mhvRLPv6IBpe37NxaZtc9erpu1kKZzE4yXdDLWfNG3NkOws2SjvbAvkUXLEHE+iyjc4IcebqzSyYtr58MluPiz/ve2feGcnJBIY7IREAoOdkEhgsBMSCQx2QiKBwU5IJFSV3kRkO4APARhX1TclbasBfA/ARgCjAG5R1dPVjrWiYxY3DB0I2k6tD8taAHBRZ7gG3eq2abPPj49ebdq2v/Iu03bvG8dM277ZoWD7z45fafb5wsZ/NW2zak9/o6UhL8vL88OTvDqw+Jpxnh8eabPGrPG84/lyo31erEy0av28+bdoN6S8erPevgngxte03Qlgh6peAWBH8jchZAlTNdiT/dZPvab5JgAPJI8fAHBzg/0ihDSYtN/Z+1X1SPL4KCo7uhJCljB1L9CpqgL2FxIR2SoiIyIycu70XL3DEUJSkjbYj4nIAAAkv8etJ6rqNlUdVtXhZas6Uw5HCKmXtMH+KIDbkse3AfhRY9whhDSLWqS37wK4HsBaETkM4G4AXwTwsIjcDuAVALfUMlh/2yQ+s+6JoO1QsdvsN9QWLlJ53/H32H16bCVw97FB0/ZP49ebtoHO8LZRhyf6zD7r8gXTdqqUTo5JI6MVtMPsc6Zkz/3xol3U08voGzK22JpxXlejizJ6nCnbr3ls3t5WbLDdvq5W5sLXKQDY5VR9yc6i27gGco7EVzXYVfVjhun9NXlFCFkS8D/oCIkEBjshkcBgJyQSGOyERAKDnZBIyLTg5OlyN75/9i1Bmye7XNUVzkT7wxUvpPLjHX2/Nm07JzaZtuOF3mB7e96WwrrFzkOadIoQTqvdzy7NCYwVw7JRWe33dW9/u5dmLzJtXhFFS3rrdmSmCeca2DsXzjgE/IKTv98ZvnaOFm259Mh8uMAp4L/mQt72/99OXWPa3t33YrD9Xcvs6/Ths+HjnS79t9mHd3ZCIoHBTkgkMNgJiQQGOyGRwGAnJBIY7IREQqbS23SpA09ObAzaetvswhYbOl5bFavCDd32vmy/nLWL57x4zrbNlmwZ6pnx8B5xk1PLzD6Hi/YUTzuS13TZzv3fOXu5afvFqcuC7W9YbmdrvaEzPL/VKDgZbKfKXcF2r4Cll313umgXJPVk2+W58HV1qmjvz3di3rZ5/FrXmbZnTtp7D5q2S+2xHnxpONh+cm632Yd3dkIigcFOSCQw2AmJBAY7IZHAYCckErJdjZ/uwpMjbwza8ufsxI+frQlv5fTVIbsG2h/1HzRto1NrTNtEIbyKDAATo+EECc/3h8/8gWk749TdmyraNePOFuzV/xeOh1eE9xbsunub+u15vHnAXt1dmbe337JW3b0Vdy8hZ21beAswADhRDCcoAcCOM+Fr5+VJ+xooO0lI65ZNmbazzrWzsc9WPHbuCysoXzjwEbNPeWW4ql25ZN+/eWcnJBIY7IREAoOdkEhgsBMSCQx2QiKBwU5IJNSy/dN2AB8CMK6qb0ra7gHwCQDHk6fdpaqPVTtWe9c8Nlx5LGg79Opas1/XWFiSOTpl10drHzhg2vbtsuvMdf/Gfv9bPxauP5Yv2HXJdj5uS2+lDnusV2+169p96u3/Zdq62sKSzK5dYckTAA5Orzdtb950yLQN5W0ZalN7OJlkvHQ82A4Au+fs2m/XGnUIAf+OdX/5HcH2A2fsa+e96+3ahj8Zu8q0zTuy158P/tK0jfRcEmzv3WNLkVf82WiwfUennVBWy539mwBuDLR/RVU3Jz9VA50Q0lqqBruqPgEgXQ4kIWTJUM939jtEZK+IbBcRe9tLQsiSIG2wfw3AZQA2AzgC4F7riSKyVURGRGSkOHEu5XCEkHpJFeyqekxVS6paBnA/gC3Oc7ep6rCqDrf12f/TTQhpLqmCXUQW1tH5MIB9jXGHENIsapHevgvgegBrReQwgLsBXC8imwEogFEAn6xlsEu7TuI7V307aDtwub0dz55zYWniGy9ea/b59hPXmTZxXvXkm23pIj8brgu38uWw3AUAk0N29tr0gJ1dteXyl0zb0Tl7ri7qDGeHtU3aY3UctiWeuzfeZNr6OmZN2++tCEus7+yxsxHHiytM2+i8Xd/t7V2jtq07vIVS36D9lfLidrte30OTbzdt5V/bdfK+2nG9aWt/IfyJd+VLBbPPrufCBepmjGsUqCHYVfVjgeavV+tHCFla8D/oCIkEBjshkcBgJyQSGOyERAKDnZBIEFXNbLDVV63TP94eLqJ3bMYuGnhmJixNTBy2JaihH9uv69xqe7ug+R5bouobtSU2i1dvdN5PHVPnuONjr51lV14Wft2r9tiDdZ22jzc5ZPvh7P6E+Z6wH3Pr7Gy+5f12Acty2T4vhTlbOizNhJ2UglOYcdYeq3vM7rfshH3N5eZtW8+hsIQ5t9aWbQs9YT+e/Y+/x/TJQ8EXwDs7IZHAYCckEhjshEQCg52QSGCwExIJDHZCIiHTvd5mJrqw5ydXBm15O8EHeSMRzRbrgHNrbKmjY9KWmrpP2La26bBslJ8tmn1W7bMzoWacrLfeUUfGsYdDrhg+5rIT9gSX2+33/LV77cE0b/uvubBt3pCMAGB6vS2liq3YYeVJ+5zliuF5FLsLNG/PfTnvyJ5ONPW+amcIzveGpcOpAVv27D4e9kMcJZ13dkIigcFOSCQw2AmJBAY7IZHAYCckEjJdjZcy0BEukYacXfoNYiTreCuqJbsUF8452y55738dk+HV0Z7f2EuglpIAAJqz+3kr9Z3Olh3tM+FjFlbYp7rYZY/VNuskjBgr3QAg5bBt2XE7mchb3Z8esP2YuNS2lY1cEnEUDdhuoPuI85qdlfCpoS7TVuwMD6hiOzKxMXwtluzcGd7ZCYkFBjshkcBgJyQSGOyERAKDnZBIYLATEgm1bP80BOBbAPpR2e5pm6reJyKrAXwPwEZUtoC6RVXtfXNQSRSY6Q/rE7nFl3czkz6AxFMDPwnCts2uCY9X6rBllZUv2tsMrd1p11wrOZtgHnp/j2mbMrq1T9nv655ckxYrcWXDf9onetWvxkxbbvhi03b0I3aSz7LusPY5darb7tNnJ61MdtnpV3mndp22eUlD4Yu13OYk5HQYfexyfDXd2YsAPqeqVwO4FsCnReRqAHcC2KGqVwDYkfxNCFmiVA12VT2iqk8njycB7AcwCOAmAA8kT3sAwM3NcpIQUj+L+s4uIhsBXANgJ4B+VT2SmI6i8jGfELJEqTnYRaQHwA8AfFZVzy60aaX4fPBLhIhsFZERERkpT9vfUQkhzaWmYBeRdlQC/UFVfSRpPiYiA4l9AMB4qK+qblPVYVUdzi23q7YQQppL1WAXEUFlP/b9qvrlBaZHAdyWPL4NwI8a7x4hpFHUkvX2bgAfB/CMiOxO2u4C8EUAD4vI7QBeAXBL1SPlgHJXWDLwthISa+sfJ83IleUc6c3LUrMorHCyxk7PmLbS8wftfpcMOSPa0pslvcwvt+fKm3t1bgderTbrnHkSVPGVQ6atz8kAO3XVBtM22xuWRbtmnOvD0SLbnFp4xe50GXFiXKvttmprZgh6tfqqBruq/gJ20t/7q/UnhCwN+B90hEQCg52QSGCwExIJDHZCIoHBTkgkZFpwMjcPdB1b/PuLJf/knUw5L4vOK27ZMbX4baPyBVvLK/XYlS/zV15u2sod9qlZ+6xdLbFsSVuO9OMVWFTPZmzxBABSNuZq2j4x+UE7s03b7HTEgV/ZJ9Tyv9Bnz2/HRLotr7xttNrOOZqYgVW0EwDml4f9HzMKjgK8sxMSDQx2QiKBwU5IJDDYCYkEBjshkcBgJyQSMpXeVPyCjmY/o0/R896uAQlx0urnnQy2mWLYkVzJflFymVMBUO3ihV5RTE9Gy5UWX9DTy5SyjgdUk97C7WcvszP2ZJN9Yrz5yBecwoyGFFnose9z0/22XOrtb2ftswcAJWc/PUse9DLlrNflSYO8sxMSCQx2QiKBwU5IJDDYCYkEBjshkZDtanwemF9hLDF6q8/WW5LXx8N7i3NWQL2aa3afRXcB4K+QmzX5AIiRw+Edz0uE8YzeCrmUjElOuS2X5787x8Z43lg5Ow/GTjQCMDPgTqSN4aOnoFjJYUVbSOCdnZBYYLATEgkMdkIigcFOSCQw2AmJBAY7IZFQVXoTkSEA30JlS2YFsE1V7xORewB8AsDx5Kl3qepj7sEUplyWJvHDlZO8w6V8i5PS4rfc8WUtp5srQ3mF4cLNnozj4clarjxo+OHXtKvNp9/umKKLM5az+1Pq8+liyWjOll0laxs153zVorMXAXxOVZ8WkV4AT4nI44ntK6r6dzUcgxDSYmrZ6+0IgCPJ40kR2Q9gsNmOEUIay6I+OInIRgDXANiZNN0hIntFZLuIrGqwb4SQBlJzsItID4AfAPisqp4F8DUAlwHYjMqd/16j31YRGRGRkfL0dANcJoSkoaZgF5F2VAL9QVV9BABU9ZiqllS1DOB+AFtCfVV1m6oOq+pwbrlTIoYQ0lSqBruICICvA9ivql9e0D6w4GkfBrCv8e4RQhpFLavx7wbwcQDPiMjupO0uAB8Tkc2oCB+jAD5Z7UCiQNusIV85mUZpMse847nbHaXJA/RkMsfmSk2exJMycywVKWQtACgb58yb33KbU+/O6ZdGgvXm3j1nzrXons808qAzH2WrtKFz3dSyGv8L4xC+pk4IWVLwP+gIiQQGOyGRwGAnJBIY7IREAoOdkEjItOAkNGVBROtwniSXUrrKzS3ej7S4RRRTvg3njGOmlSLTzmPZuLKkYPfJFZwtklJm36U5ntvPOS+eVJZqrKI9H/nZcLu7lVed/hBCXicw2AmJBAY7IZHAYCckEhjshEQCg52QSMhWegPsgoiOZJAmkcuVIBwZKk0RRSvDC/Cztbzii27BSS/rLYUMleY1pybtXm/eHnzePKY4Z57caEmKAKDeHnwNLs5pHsvbw27xhyOEvB5hsBMSCQx2QiKBwU5IJDDYCYkEBjshkZCt9CZAaZm1R5UjW1hygifHNGEvLytTSvON1qd8xJF4LDRn+yhOdpW3R1yazLyGF8SsNp61T2BKPzyJGF5moXeJWPPoZdilkOV4ZyckEhjshEQCg52QSGCwExIJDHZCIqHqaryIdAF4AkBn8vzvq+rdIrIJwEMA1gB4CsDHVdWpMFap0VVYE17OlIL9vmOuqDahhpu7Gm/ZUq50u/XdHLTB2Sm5YrrjeUkh1mq3m6iTQgmpGB2b1SVlvThXuXBq6Lm+GGpOmhqL5rZQqO3OPgfgfar6VlS2Z75RRK4F8CUAX1HVywGcBnB7DccihLSIqsGuFaaSP9uTHwXwPgDfT9ofAHBzUzwkhDSEWvdnzyc7uI4DeBzASwDOqOr5fyM4DGCwOS4SQhpBTcGuqiVV3QxgA4AtAK6sdQAR2SoiIyIyUpqaTukmIaReFrWMpapnAPwcwDsBrBSR80s0GwCMGX22qeqwqg7ne5bX5SwhJD1Vg11E1onIyuTxMgA3ANiPStB/NHnabQB+1CwnCSH1U0sizACAB0Qkj8qbw8Oq+u8i8hyAh0TkrwH8L4CvVz2SADAkD3UqzaURSdxkkQzzVrTDHix1Ao0j9ZnyldOllCZJAwDanHM2H+4oRjvgJ+ugwx5LHD/sTrZJS842VM4hy2mK4QHItYf9F2c+8nmjj3EsoIZgV9W9AK4JtL+Myvd3QsjrAP4HHSGRwGAnJBIY7IREAoOdkEhgsBMSCaKanQ4lIscBvJL8uRbAicwGt6EfF0I/LuT15sclqrouZMg02C8YWGREVYdbMjj9oB8R+sGP8YREAoOdkEhoZbBva+HYC6EfF0I/LuR3xo+WfWcnhGQLP8YTEgktCXYRuVFEDojIQRG5sxU+JH6MisgzIrJbREYyHHe7iIyLyL4FbatF5HEReTH5vapFftwjImPJnOwWkQ9m4MeQiPxcRJ4TkWdF5DNJe6Zz4viR6ZyISJeIPCkiexI//ipp3yQiO5O4+Z6IeBuZ/TaqmukPgDwqZa0uBdABYA+Aq7P2I/FlFMDaFoz7HgBvA7BvQdvfArgzeXwngC+1yI97APxFxvMxAOBtyeNeAC8AuDrrOXH8yHROUEnA7UketwPYCeBaAA8DuDVp/0cAn1rMcVtxZ98C4KCqvqyV0tMPAbipBX60DFV9AsCp1zTfhErhTiCjAp6GH5mjqkdU9enk8SQqxVEGkfGcOH5kilZoeJHXVgT7IIBDC/5uZbFKBfBTEXlKRLa2yIfz9KvqkeTxUQD9LfTlDhHZm3zMb/rXiYWIyEZU6ifsRAvn5DV+ABnPSTOKvMa+QHedqr4NwJ8A+LSIvKfVDgGVd3ZkWk/nAr4G4DJU9gg4AuDerAYWkR4APwDwWVU9u9CW5ZwE/Mh8TrSOIq8WrQj2MQBDC/42i1U2G1UdS36PA/ghWlt555iIDABA8nu8FU6o6rHkQisDuB8ZzYmItKMSYA+q6iNJc+ZzEvKjVXOSjL3oIq8WrQj2XQCuSFYWOwDcCuDRrJ0QkeUi0nv+MYAPANjn92oqj6JSuBNoYQHP88GV8GFkMCciIqjUMNyvql9eYMp0Tiw/sp6TphV5zWqF8TWrjR9EZaXzJQB/2SIfLkVFCdgD4Nks/QDwXVQ+Ds6j8t3rdlT2zNsB4EUAPwOwukV+fBvAMwD2ohJsAxn4cR0qH9H3Atid/Hww6zlx/Mh0TgC8BZUirntReWP5/IJr9kkABwH8C4DOxRyX/0FHSCTEvkBHSDQw2AmJBAY7IZHAYCckEhjshEQCg52QSGCwExIJDHZCIuH/AMOnTwykrIWpAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the image from the imgTensor values\n",
        "#no colour limitation\n",
        "imgTensor, label = datasetT[example]\n",
        "plt.imshow(imgTensor[2, 0:128, 0:128])\n",
        "# change the 0 to 1 or 2 for different color channels.\n",
        "print(\"R channel of image 0 in dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "SRRguBze6eoS",
        "outputId": "6890feac-1261-4ef7-a915-2c6f8ad6b404"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R channel of image 0 in dataset\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting the data"
      ],
      "metadata": {
        "id": "URsET3_O6r4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduce a training set plus a cross-validation set to check for over/underfitting"
      ],
      "metadata": {
        "id": "lXWfypRq68lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#length of training examples.\n",
        "m = 50000 \n",
        "\n",
        "#percentage of m dedicated to CV.  \n",
        "pCV = 0.2\n",
        "\n",
        "# give the amount of examples dedicated to CV. \n",
        "mCV = int(m*pCV)\n",
        "print(\"amount of training examples: \" + str(m - mCV))\n",
        "print(\"amount of cross validation examples: \" + str(mCV))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ext5bdcj57DS",
        "outputId": "24aef8f9-c47e-44d8-946b-a5da79c39c47"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amount of training examples: 40000\n",
            "amount of cross validation examples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This creates a function to randomly create the training and cross-validation sets according to the % split you want\n",
        "#This could also be done using a pytorch Sampler\n",
        "def splitIndices(m, pCV):\n",
        "  \"\"\" randomly shuffle a training set's indices, then split the indices into training and cross validation sets.\n",
        "   Pass in 'm', length of training set, and 'pCV', the percentage of the training set you would like \n",
        "   to dedicate to cross validation.\"\"\"\n",
        "   \n",
        "  # determine size of CV set.\n",
        "  mCV = int(m*pCV)\n",
        "\n",
        "  #create random permutation of 0 to m-1 - randomly shuffle all values from 0 to m.\n",
        "  indices = np.random.permutation(m)\n",
        "\n",
        "  #pick first mCV indices for training, and then validation.\n",
        "  return indices[mCV:], indices[:mCV]"
      ],
      "metadata": {
        "id": "ARzPJM6R6t-K"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the two sets\n",
        "trainIndices, valIndices = splitIndices(m, pCV)"
      ],
      "metadata": {
        "id": "nm_9cKix9DJl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first few indices of the training set, and first few of the validation set, as a sanity check to see that they are shuffled.\n",
        "print(\"length of training set: \" + str(len(trainIndices)))\n",
        "print(\"length of cross validation set: \" + str(len(valIndices)))\n",
        "print()\n",
        "print('sample validation indices: ' + str(list(valIndices[0:8])))\n",
        "print('sample educational indices: ' + str(list(trainIndices[0:8])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aNiIsEp9J7U",
        "outputId": "a390e116-fa9e-420e-bf8a-b58de747a9d5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set: 40000\n",
            "length of cross validation set: 10000\n",
            "\n",
            "sample validation indices: [39384, 11290, 23661, 38736, 23572, 16407, 33747, 13987]\n",
            "sample educational indices: [4041, 11666, 37584, 2349, 28477, 11533, 26980, 48812]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Internal library method (random split) to split into Train and Validate sets"
      ],
      "metadata": {
        "id": "w6-B75hq0-sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ALTERNATE CODE from Pytorch \n",
        "# PRESET CODE -- OPTIMIZED PYTORCH IMPLEMENTATION\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_ds, val_ds = random_split(datasetT, [40000, 10000])\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwHCMN_59NqS",
        "outputId": "e669d55a-83c2-4f0e-8c71-a24a331e2442"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we load the indices into groups for later stochastic gradient descent, as well as ease of programming, since these are quite large matrices."
      ],
      "metadata": {
        "id": "_gQ1un_B_af6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader"
      ],
      "metadata": {
        "id": "a88OxJYJ-qkt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What this below does is create a sampler object with SubsetRandomSampler, which creates an endlessly iterable 'list' of shuffled indices from trainIndices (just a list of arbitrary numbers).\n",
        "\n",
        "Then, in trainLoader, say if batch size = 2, 2 images (color value matrices) will be processed from datasetT using the first two indices in trainSampler. This means that there will be two sets of three 32x32 matrices, which reflects the nature that the entire dimensions of the X is technically 50000x3x32x32 (or if our batch size is say 100, 100x3x32x32 for each batch)"
      ],
      "metadata": {
        "id": "UNgb9VJ2_lxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batchSize = 100\n",
        "\n",
        "# TRAIN SET\n",
        "\n",
        "# training sampler and data loader - creates a SubsetRandomSampler object that takes random samples of the numbers in trainIndices, or random indices.\n",
        "trainSampler = SubsetRandomSampler(trainIndices)\n",
        "\n",
        "\n",
        "# training loader - creates a dataloader object which takes the indices from trainSampler, \n",
        "# and when given batchSize, takes random batches of batchSize from the indices list, and then pairs it with\n",
        "# the respective dataset in datasetT\n",
        "trainLoader = DataLoader(datasetT, batchSize, sampler=trainSampler)\n",
        "\n",
        "print(list(trainLoader))\n",
        "\n",
        "# VALIDATION SET\n",
        "\n",
        "valSampler = SubsetRandomSampler(valIndices)\n",
        "valLoader = DataLoader(datasetT, batchSize, sampler=valSampler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSA_GNah_eKj",
        "outputId": "68c89a60-d6be-4c70-eecd-3b50926608f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to correct shape"
      ],
      "metadata": {
        "id": "4m9pY7r0Adq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# this will dictate the rows of the theta matrix\n",
        "inputSize = 3*32*32\n",
        "\n",
        "# this will dictate the columns of the theta matrix\n",
        "numClasses = 10\n",
        "\n",
        "# create our linear regression model (nn.Linear creates bias terms for us)\n",
        "model = nn.Linear(inputSize, numClasses)"
      ],
      "metadata": {
        "id": "-CzicAYnAcVb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(inputSize, numClasses)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        xb = xb.reshape(-1, 3072)\n",
        "        out = self.linear(xb)\n",
        "        return out\n",
        "    \n",
        "model = CIFAR10()"
      ],
      "metadata": {
        "id": "ylMjOlLwAGqZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the shape\n",
        "print(model.linear.weight.shape)\n",
        "print(model.linear.bias.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoOt0Ov0s10h",
        "outputId": "1a8d4020-eced-4a58-9753-c5d46d56727a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 3072])\n",
            "torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in trainLoader:\n",
        "  outputs = model(images)\n",
        "  break\n",
        "\n",
        "print('outputs.shape :', outputs.shape)\n",
        "\n",
        "print('sample outputs :\\n', outputs[:2]) # print 2 out of the 100 rows of the total output vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygMHC7Vus-UX",
        "outputId": "46648b36-ada7-4b48-e32f-5b14bcdd1349"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outputs.shape : torch.Size([100, 10])\n",
            "sample outputs :\n",
            " tensor([[-0.2107,  0.0328, -0.1374, -0.2890,  0.2296, -0.1016,  0.2487, -0.1453,\n",
            "         -0.1417,  0.5365],\n",
            "        [ 0.0566, -0.5749,  0.0190, -0.7939,  0.3332,  0.0216, -0.1197, -0.1276,\n",
            "         -0.1144,  0.4933]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.nn.functional is an internal layer which can be connected to other layers \n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "hkSx67eStEbG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#specify the dimensiont hat SoftMax will be applied to\n",
        "# apply the softmax for each output row in our 100 x 10 output (with batch size 100)\n",
        "probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "# look at some sample probabilities\n",
        "print(\"sample probabilities:\\n\", probs[:2].data)\n",
        "# add up the probabilities of each row for a sanity check that they equal 1 now\n",
        "print(sum(list(probs[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p-Ix1T1twIf",
        "outputId": "8a7fe39b-50c0-442c-c9b2-15e5707381d1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample probabilities:\n",
            " tensor([[0.0783, 0.0998, 0.0842, 0.0724, 0.1215, 0.0873, 0.1239, 0.0835, 0.0839,\n",
            "         0.1652],\n",
            "        [0.1079, 0.0574, 0.1039, 0.0461, 0.1423, 0.1042, 0.0905, 0.0898, 0.0910,\n",
            "         0.1670]])\n",
            "tensor(1., grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxProbs, preds = torch.max(probs, dim=1) #torch.max returns the max value itself (maxProbs) as well as the index of the prediction (preds)\n",
        "print(preds)\n",
        "print(maxProbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtPLjEVBt6vD",
        "outputId": "098b4ddc-c20f-4da4-b2d7-6ffe59d869e4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 4, 9,\n",
            "        9, 9, 9, 9, 9, 9, 4, 9, 9, 4, 2, 9, 9, 9, 9, 9, 9, 0, 9, 9, 2, 9, 9, 9,\n",
            "        2, 9, 9, 9, 9, 9, 9, 9, 2, 9, 9, 2, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 4,\n",
            "        9, 9, 9, 9, 9, 9, 9, 9, 4, 9, 9, 9, 4, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
            "        9, 0, 9, 9])\n",
            "tensor([0.1652, 0.1670, 0.1490, 0.1799, 0.1379, 0.1677, 0.1265, 0.1574, 0.1544,\n",
            "        0.1828, 0.1427, 0.1486, 0.1614, 0.1488, 0.1446, 0.1389, 0.1314, 0.1949,\n",
            "        0.1402, 0.1532, 0.2052, 0.1562, 0.1336, 0.1603, 0.1501, 0.1399, 0.1445,\n",
            "        0.1277, 0.1483, 0.1703, 0.1638, 0.1768, 0.1523, 0.1528, 0.1347, 0.1809,\n",
            "        0.1849, 0.1720, 0.1425, 0.1958, 0.1276, 0.1475, 0.1867, 0.1735, 0.1346,\n",
            "        0.1469, 0.1590, 0.1785, 0.1355, 0.2063, 0.1371, 0.1782, 0.1555, 0.1531,\n",
            "        0.1663, 0.1629, 0.1310, 0.1404, 0.1697, 0.1170, 0.1535, 0.1652, 0.1452,\n",
            "        0.1641, 0.1578, 0.1387, 0.1519, 0.1677, 0.1549, 0.1421, 0.1628, 0.1402,\n",
            "        0.2203, 0.1344, 0.1791, 0.1257, 0.1342, 0.1372, 0.1423, 0.1443, 0.1445,\n",
            "        0.1479, 0.1625, 0.1634, 0.1444, 0.1454, 0.1441, 0.1548, 0.1269, 0.1351,\n",
            "        0.1463, 0.1484, 0.1554, 0.1259, 0.1519, 0.1514, 0.1523, 0.1588, 0.1304,\n",
            "        0.1541], grad_fn=<MaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation and Cost function"
      ],
      "metadata": {
        "id": "QdN8LYmnuDXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels==preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4wdL-0GuAGl",
        "outputId": "8f74d1e5-926d-42da-ab28-d9680a28daff"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False, False, False,  True, False, False,\n",
              "        False, False, False,  True, False,  True, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False,  True, False, False, False,  True, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False,  True,  True, False, False, False, False, False,\n",
              "        False, False, False,  True,  True, False, False, False, False, False,\n",
              "        False, False, False, False, False,  True, False,  True, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def accuracy(preds, labels):\n",
        "  return torch.sum(labels==preds).item() / len(labels)"
      ],
      "metadata": {
        "id": "z3S3fA0ruHl2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use stochastic gradient descent to update our algorithm. Choose a slightly larger learningRate, a hyperparameter, than last time.\n",
        "learningRate = 0.001\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
      ],
      "metadata": {
        "id": "wlLBkt0DuNTn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "U_tn9yAaucEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# recall that xb is the X (a list batchSize long of 3x32x32 images) for a batch. yb is the corresponding labels for those images.\n",
        "\n",
        "def lossBatch(model, lossFn, xb, yb, opt=None, metric=None):\n",
        "  # calculate the loss\n",
        "  preds = model(xb)\n",
        "  loss = lossFn(preds, yb)\n",
        "\n",
        "  if opt is not None:\n",
        "    # compute gradients\n",
        "    loss.backward()\n",
        "    # update parameters\n",
        "    opt.step()\n",
        "    # reset gradients to 0 (don't want to calculate second derivatives!)\n",
        "    opt.zero_grad()\n",
        "\n",
        "  metricResult = None\n",
        "  if metric is not None:\n",
        "    metricResult = metric(preds, yb)\n",
        "\n",
        "  return loss.item(), len(xb),  metricResult"
      ],
      "metadata": {
        "id": "gLeicXKkuZmq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, lossFn, validDL, metric=None):\n",
        "  #with torch.no_grad (this was causing an error)\n",
        "  \n",
        "  # pass each batch of the validation set through the model to form a multidimensional list (holding loss, length and metric for each batch)\n",
        "  # the reason why we made optimization optional is so we can reuse the function here\n",
        "  results = [lossBatch(model, lossFn, xb, yb, metric=metric,) for xb,yb in validDL]\n",
        "\n",
        "  # separate losses, counts and metrics\n",
        "  losses, nums, metrics = zip(*results)\n",
        "\n",
        "  # total size of the dataset (we keep track of lengths of batches since dataset might not be perfectly divisible by batch size)\n",
        "  total = np.sum(nums)\n",
        "\n",
        "  # find average total loss over all batches in validation (remember these are all vectors doing element wise operations.)\n",
        "  avgLoss = np.sum(np.multiply(losses, nums))/total\n",
        "\n",
        "  # if there is a metric passed, compute the average metric\n",
        "  if metric is not None:\n",
        "    # avg of metric accross batches\n",
        "    avgMetric = np.sum(np.multiply(metrics, nums)) / total\n",
        "\n",
        "  return avgLoss, total, avgMetric"
      ],
      "metadata": {
        "id": "Ii05Q6H5uhwa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1) # underscore discards the max value itself, we don't care about that\n",
        "  return torch.sum(preds == labels).item() / len(preds)"
      ],
      "metadata": {
        "id": "eKzZn9IhuoQm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "E = evaluate(model, lossFn, valLoader, metric=accuracy)\n",
        "\n",
        "print(\"training set loss: \", loss)\n",
        "print(\"cross validation set loss: \", E[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "GLhPFy4fuq1s",
        "outputId": "89339457-0ba1-4a02-faf0-21725f872e50"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-844ea283c264>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training set loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cross validation set loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lossFn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recap\n",
        "\n",
        "First, we load our CIFAR-10 dataset.\n",
        "\n",
        "Then, we upload images in batches of 100 at a time.\n",
        "\n",
        "Then, we convert our images into 3x32x32 tensors. This makes our batch matrix 100 x 3 x 32 x 32 in dimensions.\n",
        "\n",
        "Then, we pass each batch into the CIFAR10 model, which converts the tensors from 100 x 3 x 32 x 32 to 100 x 3072.\n",
        "\n",
        "Then, we multiply it by the weights matrix, which is [10 x 3072], which is transposed to be multiplied by each tensor batch\n",
        "This multiplication gives a 100 x 10 results matrix, with logits, and we add the bias.\n",
        "\n",
        "Then, softmax is applied on the logits to convert them into probabilities.\n",
        "\n",
        "Then, cross entropy is performed on the probabilites matrix to give a continuous and differentiable cost function.\n",
        "\n",
        "Then, cross entropy from all the different batches is combined to give a total training loss.\n",
        "\n",
        "Then we calculate the partial derivatives of this cross entropy function with respect to every one of the 10x3072 weights and biases.\n",
        "\n",
        "Then, we subtract the gradient (the vector of all 10x3072 partial derivatives) from the vector of current thetas, for each batch. (so, youre subtracting from theta 100 times).\n",
        "\n",
        "We do step 11 for each number of epochs."
      ],
      "metadata": {
        "id": "mR11A05bu5oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine model and optimizer\n",
        "learningRate = 0.009\n",
        "model = CIFAR10()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
      ],
      "metadata": {
        "id": "5YdnRpEGu9Rd"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainList = fit(100, model, lossFn, optimizer, trainLoader, valLoader, metric=accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "3sBQOWhfu_5t",
        "outputId": "90501738-dcda-4723-87c4-78099082bf2d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c1806700501b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlossFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'fit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7okwDCovUP5",
        "outputId": "6d2ea41c-35eb-4919-9f8d-df972316abbc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testLoader = DataLoader(test, batchSize)"
      ],
      "metadata": {
        "id": "jAVSDKSsvXtd"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avgLoss, total, avgMetric = evaluate(model, F.cross_entropy, testLoader, metric=accuracy)\n",
        "print(\"test set accuracy: \\n\", avgMetric)\n",
        "avgLoss, total, avgMetric = evaluate(model, F.cross_entropy, valLoader, metric=accuracy)\n",
        "print(\"cross validation set accuracy: \\n\",avgMetric)\n",
        "avgLoss, total, avgMetric = evaluate(model, F.cross_entropy, trainLoader, metric=accuracy)\n",
        "print(\"training set accuracy: \\n\",avgMetric)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44qC9dP5vaE2",
        "outputId": "ec2b8521-b41f-4134-c4bf-a41d09bfb68d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set accuracy: \n",
            " 0.0705\n",
            "cross validation set accuracy: \n",
            " 0.0707\n",
            "training set accuracy: \n",
            " 0.0691\n"
          ]
        }
      ]
    }
  ]
}